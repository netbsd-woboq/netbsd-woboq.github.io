<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>fts3_tokenizer.h source code [netbsd/usr.sbin/makemandb/fts3_tokenizer.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="sqlite3_tokenizer,sqlite3_tokenizer_cursor,sqlite3_tokenizer_module "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'netbsd/usr.sbin/makemandb/fts3_tokenizer.h'; var root_path = '../../..'; var data_path = 'https://code.woboq.org/data'; var ecma_script_api_version = 2;</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../..'>netbsd</a>/<a href='..'>usr.sbin</a>/<a href='./'>makemandb</a>/<a href='fts3_tokenizer.h.html'>fts3_tokenizer.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/*</i></td></tr>
<tr><th id="2">2</th><td><i>** 2006 July 10</i></td></tr>
<tr><th id="3">3</th><td><i>**</i></td></tr>
<tr><th id="4">4</th><td><i>** The author disclaims copyright to this source code.</i></td></tr>
<tr><th id="5">5</th><td><i>**</i></td></tr>
<tr><th id="6">6</th><td><i>*************************************************************************</i></td></tr>
<tr><th id="7">7</th><td><i>** Defines the interface to tokenizers used by fulltext-search.  There</i></td></tr>
<tr><th id="8">8</th><td><i>** are three basic components:</i></td></tr>
<tr><th id="9">9</th><td><i>**</i></td></tr>
<tr><th id="10">10</th><td><i>** sqlite3_tokenizer_module is a singleton defining the tokenizer</i></td></tr>
<tr><th id="11">11</th><td><i>** interface functions.  This is essentially the class structure for</i></td></tr>
<tr><th id="12">12</th><td><i>** tokenizers.</i></td></tr>
<tr><th id="13">13</th><td><i>**</i></td></tr>
<tr><th id="14">14</th><td><i>** sqlite3_tokenizer is used to define a particular tokenizer, perhaps</i></td></tr>
<tr><th id="15">15</th><td><i>** including customization information defined at creation time.</i></td></tr>
<tr><th id="16">16</th><td><i>**</i></td></tr>
<tr><th id="17">17</th><td><i>** sqlite3_tokenizer_cursor is generated by a tokenizer to generate</i></td></tr>
<tr><th id="18">18</th><td><i>** tokens from a particular input.</i></td></tr>
<tr><th id="19">19</th><td><i>*/</i></td></tr>
<tr><th id="20">20</th><td><u>#<span data-ppcond="20">ifndef</span> <span class="macro" data-ref="_M/_FTS3_TOKENIZER_H_">_FTS3_TOKENIZER_H_</span></u></td></tr>
<tr><th id="21">21</th><td><u>#define <dfn class="macro" id="_M/_FTS3_TOKENIZER_H_" data-ref="_M/_FTS3_TOKENIZER_H_">_FTS3_TOKENIZER_H_</dfn></u></td></tr>
<tr><th id="22">22</th><td></td></tr>
<tr><th id="23">23</th><td><i>/* TODO(shess) Only used for SQLITE_OK and SQLITE_DONE at this time.</i></td></tr>
<tr><th id="24">24</th><td><i>** If tokenizers are to be allowed to call sqlite3_*() functions, then</i></td></tr>
<tr><th id="25">25</th><td><i>** we will need a way to register the API consistently.</i></td></tr>
<tr><th id="26">26</th><td><i>*/</i></td></tr>
<tr><th id="27">27</th><td><u>#include <a href="../../objdir.amd64/destdir.amd64/usr/include/sqlite3.h.html">"sqlite3.h"</a></u></td></tr>
<tr><th id="28">28</th><td></td></tr>
<tr><th id="29">29</th><td><i>/*</i></td></tr>
<tr><th id="30">30</th><td><i>** Structures used by the tokenizer interface. When a new tokenizer</i></td></tr>
<tr><th id="31">31</th><td><i>** implementation is registered, the caller provides a pointer to</i></td></tr>
<tr><th id="32">32</th><td><i>** an sqlite3_tokenizer_module containing pointers to the callback</i></td></tr>
<tr><th id="33">33</th><td><i>** functions that make up an implementation.</i></td></tr>
<tr><th id="34">34</th><td><i>**</i></td></tr>
<tr><th id="35">35</th><td><i>** When an fts3 table is created, it passes any arguments passed to</i></td></tr>
<tr><th id="36">36</th><td><i>** the tokenizer clause of the CREATE VIRTUAL TABLE statement to the</i></td></tr>
<tr><th id="37">37</th><td><i>** sqlite3_tokenizer_module.xCreate() function of the requested tokenizer</i></td></tr>
<tr><th id="38">38</th><td><i>** implementation. The xCreate() function in turn returns an </i></td></tr>
<tr><th id="39">39</th><td><i>** sqlite3_tokenizer structure representing the specific tokenizer to</i></td></tr>
<tr><th id="40">40</th><td><i>** be used for the fts3 table (customized by the tokenizer clause arguments).</i></td></tr>
<tr><th id="41">41</th><td><i>**</i></td></tr>
<tr><th id="42">42</th><td><i>** To tokenize an input buffer, the sqlite3_tokenizer_module.xOpen()</i></td></tr>
<tr><th id="43">43</th><td><i>** method is called. It returns an sqlite3_tokenizer_cursor object</i></td></tr>
<tr><th id="44">44</th><td><i>** that may be used to tokenize a specific input buffer based on</i></td></tr>
<tr><th id="45">45</th><td><i>** the tokenization rules supplied by a specific sqlite3_tokenizer</i></td></tr>
<tr><th id="46">46</th><td><i>** object.</i></td></tr>
<tr><th id="47">47</th><td><i>*/</i></td></tr>
<tr><th id="48">48</th><td><b>typedef</b> <b>struct</b> <a class="type" href="#sqlite3_tokenizer_module" title='sqlite3_tokenizer_module' data-ref="sqlite3_tokenizer_module" data-ref-filename="sqlite3_tokenizer_module">sqlite3_tokenizer_module</a> <dfn class="typedef" id="sqlite3_tokenizer_module" title='sqlite3_tokenizer_module' data-type='struct sqlite3_tokenizer_module' data-ref="sqlite3_tokenizer_module" data-ref-filename="sqlite3_tokenizer_module">sqlite3_tokenizer_module</dfn>;</td></tr>
<tr><th id="49">49</th><td><b>typedef</b> <b>struct</b> <a class="type" href="#sqlite3_tokenizer" title='sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</a> <dfn class="typedef" id="sqlite3_tokenizer" title='sqlite3_tokenizer' data-type='struct sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</dfn>;</td></tr>
<tr><th id="50">50</th><td><b>typedef</b> <b>struct</b> <a class="type" href="#sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</a> <dfn class="typedef" id="sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-type='struct sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</dfn>;</td></tr>
<tr><th id="51">51</th><td></td></tr>
<tr><th id="52">52</th><td><b>struct</b> <dfn class="type def" id="sqlite3_tokenizer_module" title='sqlite3_tokenizer_module' data-ref="sqlite3_tokenizer_module" data-ref-filename="sqlite3_tokenizer_module">sqlite3_tokenizer_module</dfn> {</td></tr>
<tr><th id="53">53</th><td></td></tr>
<tr><th id="54">54</th><td>  <i>/*</i></td></tr>
<tr><th id="55">55</th><td><i>  ** Structure version. Should always be set to 0 or 1.</i></td></tr>
<tr><th id="56">56</th><td><i>  */</i></td></tr>
<tr><th id="57">57</th><td>  <em>int</em> <dfn class="decl field" id="sqlite3_tokenizer_module::iVersion" title='sqlite3_tokenizer_module::iVersion' data-ref="sqlite3_tokenizer_module::iVersion" data-ref-filename="sqlite3_tokenizer_module..iVersion">iVersion</dfn>;</td></tr>
<tr><th id="58">58</th><td></td></tr>
<tr><th id="59">59</th><td>  <i>/*</i></td></tr>
<tr><th id="60">60</th><td><i>  ** Create a new tokenizer. The values in the argv[] array are the</i></td></tr>
<tr><th id="61">61</th><td><i>  ** arguments passed to the "tokenizer" clause of the CREATE VIRTUAL</i></td></tr>
<tr><th id="62">62</th><td><i>  ** TABLE statement that created the fts3 table. For example, if</i></td></tr>
<tr><th id="63">63</th><td><i>  ** the following SQL is executed:</i></td></tr>
<tr><th id="64">64</th><td><i>  **</i></td></tr>
<tr><th id="65">65</th><td><i>  **   CREATE .. USING fts3( ... , tokenizer &lt;tokenizer-name&gt; arg1 arg2)</i></td></tr>
<tr><th id="66">66</th><td><i>  **</i></td></tr>
<tr><th id="67">67</th><td><i>  ** then argc is set to 2, and the argv[] array contains pointers</i></td></tr>
<tr><th id="68">68</th><td><i>  ** to the strings "arg1" and "arg2".</i></td></tr>
<tr><th id="69">69</th><td><i>  **</i></td></tr>
<tr><th id="70">70</th><td><i>  ** This method should return either SQLITE_OK (0), or an SQLite error </i></td></tr>
<tr><th id="71">71</th><td><i>  ** code. If SQLITE_OK is returned, then *ppTokenizer should be set</i></td></tr>
<tr><th id="72">72</th><td><i>  ** to point at the newly created tokenizer structure. The generic</i></td></tr>
<tr><th id="73">73</th><td><i>  ** sqlite3_tokenizer.pModule variable should not be initialized by</i></td></tr>
<tr><th id="74">74</th><td><i>  ** this callback. The caller will do so.</i></td></tr>
<tr><th id="75">75</th><td><i>  */</i></td></tr>
<tr><th id="76">76</th><td>  <em>int</em> (*<dfn class="decl field" id="sqlite3_tokenizer_module::xCreate" title='sqlite3_tokenizer_module::xCreate' data-ref="sqlite3_tokenizer_module::xCreate" data-ref-filename="sqlite3_tokenizer_module..xCreate">xCreate</dfn>)(</td></tr>
<tr><th id="77">77</th><td>    <em>int</em> <dfn class="local col1 decl" id="1argc" title='argc' data-type='int' data-ref="1argc" data-ref-filename="1argc">argc</dfn>,                           <i>/* Size of argv array */</i></td></tr>
<tr><th id="78">78</th><td>    <em>const</em> <em>char</em> *<em>const</em>*<dfn class="local col2 decl" id="2argv" title='argv' data-type='const char *const *' data-ref="2argv" data-ref-filename="2argv">argv</dfn>,             <i>/* Tokenizer argument strings */</i></td></tr>
<tr><th id="79">79</th><td>    <a class="typedef" href="#sqlite3_tokenizer" title='sqlite3_tokenizer' data-type='struct sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</a> **<dfn class="local col3 decl" id="3ppTokenizer" title='ppTokenizer' data-type='sqlite3_tokenizer **' data-ref="3ppTokenizer" data-ref-filename="3ppTokenizer">ppTokenizer</dfn>     <i>/* OUT: Created tokenizer */</i></td></tr>
<tr><th id="80">80</th><td>  );</td></tr>
<tr><th id="81">81</th><td></td></tr>
<tr><th id="82">82</th><td>  <i>/*</i></td></tr>
<tr><th id="83">83</th><td><i>  ** Destroy an existing tokenizer. The fts3 module calls this method</i></td></tr>
<tr><th id="84">84</th><td><i>  ** exactly once for each successful call to xCreate().</i></td></tr>
<tr><th id="85">85</th><td><i>  */</i></td></tr>
<tr><th id="86">86</th><td>  <em>int</em> (*<dfn class="decl field" id="sqlite3_tokenizer_module::xDestroy" title='sqlite3_tokenizer_module::xDestroy' data-ref="sqlite3_tokenizer_module::xDestroy" data-ref-filename="sqlite3_tokenizer_module..xDestroy">xDestroy</dfn>)(<a class="typedef" href="#sqlite3_tokenizer" title='sqlite3_tokenizer' data-type='struct sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</a> *<dfn class="local col4 decl" id="4pTokenizer" title='pTokenizer' data-type='sqlite3_tokenizer *' data-ref="4pTokenizer" data-ref-filename="4pTokenizer">pTokenizer</dfn>);</td></tr>
<tr><th id="87">87</th><td></td></tr>
<tr><th id="88">88</th><td>  <i>/*</i></td></tr>
<tr><th id="89">89</th><td><i>  ** Create a tokenizer cursor to tokenize an input buffer. The caller</i></td></tr>
<tr><th id="90">90</th><td><i>  ** is responsible for ensuring that the input buffer remains valid</i></td></tr>
<tr><th id="91">91</th><td><i>  ** until the cursor is closed (using the xClose() method). </i></td></tr>
<tr><th id="92">92</th><td><i>  */</i></td></tr>
<tr><th id="93">93</th><td>  <em>int</em> (*<dfn class="decl field" id="sqlite3_tokenizer_module::xOpen" title='sqlite3_tokenizer_module::xOpen' data-ref="sqlite3_tokenizer_module::xOpen" data-ref-filename="sqlite3_tokenizer_module..xOpen">xOpen</dfn>)(</td></tr>
<tr><th id="94">94</th><td>    <a class="typedef" href="#sqlite3_tokenizer" title='sqlite3_tokenizer' data-type='struct sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</a> *<dfn class="local col5 decl" id="5pTokenizer" title='pTokenizer' data-type='sqlite3_tokenizer *' data-ref="5pTokenizer" data-ref-filename="5pTokenizer">pTokenizer</dfn>,       <i>/* Tokenizer object */</i></td></tr>
<tr><th id="95">95</th><td>    <em>const</em> <em>char</em> *<dfn class="local col6 decl" id="6pInput" title='pInput' data-type='const char *' data-ref="6pInput" data-ref-filename="6pInput">pInput</dfn>, <em>int</em> <dfn class="local col7 decl" id="7nBytes" title='nBytes' data-type='int' data-ref="7nBytes" data-ref-filename="7nBytes">nBytes</dfn>,      <i>/* Input buffer */</i></td></tr>
<tr><th id="96">96</th><td>    <a class="typedef" href="#sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-type='struct sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</a> **<dfn class="local col8 decl" id="8ppCursor" title='ppCursor' data-type='sqlite3_tokenizer_cursor **' data-ref="8ppCursor" data-ref-filename="8ppCursor">ppCursor</dfn>  <i>/* OUT: Created tokenizer cursor */</i></td></tr>
<tr><th id="97">97</th><td>  );</td></tr>
<tr><th id="98">98</th><td></td></tr>
<tr><th id="99">99</th><td>  <i>/*</i></td></tr>
<tr><th id="100">100</th><td><i>  ** Destroy an existing tokenizer cursor. The fts3 module calls this </i></td></tr>
<tr><th id="101">101</th><td><i>  ** method exactly once for each successful call to xOpen().</i></td></tr>
<tr><th id="102">102</th><td><i>  */</i></td></tr>
<tr><th id="103">103</th><td>  <em>int</em> (*<dfn class="decl field" id="sqlite3_tokenizer_module::xClose" title='sqlite3_tokenizer_module::xClose' data-ref="sqlite3_tokenizer_module::xClose" data-ref-filename="sqlite3_tokenizer_module..xClose">xClose</dfn>)(<a class="typedef" href="#sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-type='struct sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</a> *<dfn class="local col9 decl" id="9pCursor" title='pCursor' data-type='sqlite3_tokenizer_cursor *' data-ref="9pCursor" data-ref-filename="9pCursor">pCursor</dfn>);</td></tr>
<tr><th id="104">104</th><td></td></tr>
<tr><th id="105">105</th><td>  <i>/*</i></td></tr>
<tr><th id="106">106</th><td><i>  ** Retrieve the next token from the tokenizer cursor pCursor. This</i></td></tr>
<tr><th id="107">107</th><td><i>  ** method should either return SQLITE_OK and set the values of the</i></td></tr>
<tr><th id="108">108</th><td><i>  ** "OUT" variables identified below, or SQLITE_DONE to indicate that</i></td></tr>
<tr><th id="109">109</th><td><i>  ** the end of the buffer has been reached, or an SQLite error code.</i></td></tr>
<tr><th id="110">110</th><td><i>  **</i></td></tr>
<tr><th id="111">111</th><td><i>  ** *ppToken should be set to point at a buffer containing the </i></td></tr>
<tr><th id="112">112</th><td><i>  ** normalized version of the token (i.e. after any case-folding and/or</i></td></tr>
<tr><th id="113">113</th><td><i>  ** stemming has been performed). *pnBytes should be set to the length</i></td></tr>
<tr><th id="114">114</th><td><i>  ** of this buffer in bytes. The input text that generated the token is</i></td></tr>
<tr><th id="115">115</th><td><i>  ** identified by the byte offsets returned in *piStartOffset and</i></td></tr>
<tr><th id="116">116</th><td><i>  ** *piEndOffset. *piStartOffset should be set to the index of the first</i></td></tr>
<tr><th id="117">117</th><td><i>  ** byte of the token in the input buffer. *piEndOffset should be set</i></td></tr>
<tr><th id="118">118</th><td><i>  ** to the index of the first byte just past the end of the token in</i></td></tr>
<tr><th id="119">119</th><td><i>  ** the input buffer.</i></td></tr>
<tr><th id="120">120</th><td><i>  **</i></td></tr>
<tr><th id="121">121</th><td><i>  ** The buffer *ppToken is set to point at is managed by the tokenizer</i></td></tr>
<tr><th id="122">122</th><td><i>  ** implementation. It is only required to be valid until the next call</i></td></tr>
<tr><th id="123">123</th><td><i>  ** to xNext() or xClose(). </i></td></tr>
<tr><th id="124">124</th><td><i>  */</i></td></tr>
<tr><th id="125">125</th><td>  <i>/* TODO(shess) current implementation requires pInput to be</i></td></tr>
<tr><th id="126">126</th><td><i>  ** nul-terminated.  This should either be fixed, or pInput/nBytes</i></td></tr>
<tr><th id="127">127</th><td><i>  ** should be converted to zInput.</i></td></tr>
<tr><th id="128">128</th><td><i>  */</i></td></tr>
<tr><th id="129">129</th><td>  <em>int</em> (*<dfn class="decl field" id="sqlite3_tokenizer_module::xNext" title='sqlite3_tokenizer_module::xNext' data-ref="sqlite3_tokenizer_module::xNext" data-ref-filename="sqlite3_tokenizer_module..xNext">xNext</dfn>)(</td></tr>
<tr><th id="130">130</th><td>    <a class="typedef" href="#sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-type='struct sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</a> *<dfn class="local col0 decl" id="10pCursor" title='pCursor' data-type='sqlite3_tokenizer_cursor *' data-ref="10pCursor" data-ref-filename="10pCursor">pCursor</dfn>,   <i>/* Tokenizer cursor */</i></td></tr>
<tr><th id="131">131</th><td>    <em>const</em> <em>char</em> **<dfn class="local col1 decl" id="11ppToken" title='ppToken' data-type='const char **' data-ref="11ppToken" data-ref-filename="11ppToken">ppToken</dfn>, <em>int</em> *<dfn class="local col2 decl" id="12pnBytes" title='pnBytes' data-type='int *' data-ref="12pnBytes" data-ref-filename="12pnBytes">pnBytes</dfn>,  <i>/* OUT: Normalized text for token */</i></td></tr>
<tr><th id="132">132</th><td>    <em>int</em> *<dfn class="local col3 decl" id="13piStartOffset" title='piStartOffset' data-type='int *' data-ref="13piStartOffset" data-ref-filename="13piStartOffset">piStartOffset</dfn>,  <i>/* OUT: Byte offset of token in input buffer */</i></td></tr>
<tr><th id="133">133</th><td>    <em>int</em> *<dfn class="local col4 decl" id="14piEndOffset" title='piEndOffset' data-type='int *' data-ref="14piEndOffset" data-ref-filename="14piEndOffset">piEndOffset</dfn>,    <i>/* OUT: Byte offset of end of token in input buffer */</i></td></tr>
<tr><th id="134">134</th><td>    <em>int</em> *<dfn class="local col5 decl" id="15piPosition" title='piPosition' data-type='int *' data-ref="15piPosition" data-ref-filename="15piPosition">piPosition</dfn>      <i>/* OUT: Number of tokens returned before this one */</i></td></tr>
<tr><th id="135">135</th><td>  );</td></tr>
<tr><th id="136">136</th><td></td></tr>
<tr><th id="137">137</th><td>  <i>/***********************************************************************</i></td></tr>
<tr><th id="138">138</th><td><i>  ** Methods below this point are only available if iVersion&gt;=1.</i></td></tr>
<tr><th id="139">139</th><td><i>  */</i></td></tr>
<tr><th id="140">140</th><td></td></tr>
<tr><th id="141">141</th><td>  <i>/* </i></td></tr>
<tr><th id="142">142</th><td><i>  ** Configure the language id of a tokenizer cursor.</i></td></tr>
<tr><th id="143">143</th><td><i>  */</i></td></tr>
<tr><th id="144">144</th><td>  <em>int</em> (*<dfn class="decl field" id="sqlite3_tokenizer_module::xLanguageid" title='sqlite3_tokenizer_module::xLanguageid' data-ref="sqlite3_tokenizer_module::xLanguageid" data-ref-filename="sqlite3_tokenizer_module..xLanguageid">xLanguageid</dfn>)(<a class="typedef" href="#sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-type='struct sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</a> *<dfn class="local col6 decl" id="16pCsr" title='pCsr' data-type='sqlite3_tokenizer_cursor *' data-ref="16pCsr" data-ref-filename="16pCsr">pCsr</dfn>, <em>int</em> <dfn class="local col7 decl" id="17iLangid" title='iLangid' data-type='int' data-ref="17iLangid" data-ref-filename="17iLangid">iLangid</dfn>);</td></tr>
<tr><th id="145">145</th><td>};</td></tr>
<tr><th id="146">146</th><td></td></tr>
<tr><th id="147">147</th><td><b>struct</b> <dfn class="type def" id="sqlite3_tokenizer" title='sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</dfn> {</td></tr>
<tr><th id="148">148</th><td>  <em>const</em> <a class="typedef" href="#sqlite3_tokenizer_module" title='sqlite3_tokenizer_module' data-type='struct sqlite3_tokenizer_module' data-ref="sqlite3_tokenizer_module" data-ref-filename="sqlite3_tokenizer_module">sqlite3_tokenizer_module</a> *<dfn class="decl field" id="sqlite3_tokenizer::pModule" title='sqlite3_tokenizer::pModule' data-ref="sqlite3_tokenizer::pModule" data-ref-filename="sqlite3_tokenizer..pModule">pModule</dfn>;  <i>/* The module for this tokenizer */</i></td></tr>
<tr><th id="149">149</th><td>  <i>/* Tokenizer implementations will typically add additional fields */</i></td></tr>
<tr><th id="150">150</th><td>};</td></tr>
<tr><th id="151">151</th><td></td></tr>
<tr><th id="152">152</th><td><b>struct</b> <dfn class="type def" id="sqlite3_tokenizer_cursor" title='sqlite3_tokenizer_cursor' data-ref="sqlite3_tokenizer_cursor" data-ref-filename="sqlite3_tokenizer_cursor">sqlite3_tokenizer_cursor</dfn> {</td></tr>
<tr><th id="153">153</th><td>  <a class="typedef" href="#sqlite3_tokenizer" title='sqlite3_tokenizer' data-type='struct sqlite3_tokenizer' data-ref="sqlite3_tokenizer" data-ref-filename="sqlite3_tokenizer">sqlite3_tokenizer</a> *<dfn class="decl field" id="sqlite3_tokenizer_cursor::pTokenizer" title='sqlite3_tokenizer_cursor::pTokenizer' data-ref="sqlite3_tokenizer_cursor::pTokenizer" data-ref-filename="sqlite3_tokenizer_cursor..pTokenizer">pTokenizer</dfn>;       <i>/* Tokenizer for this cursor. */</i></td></tr>
<tr><th id="154">154</th><td>  <i>/* Tokenizer implementations will typically add additional fields */</i></td></tr>
<tr><th id="155">155</th><td>};</td></tr>
<tr><th id="156">156</th><td></td></tr>
<tr><th id="157">157</th><td><em>int</em> <dfn class="decl fn" id="fts3_global_term_cnt" title='fts3_global_term_cnt' data-ref="fts3_global_term_cnt" data-ref-filename="fts3_global_term_cnt">fts3_global_term_cnt</dfn>(<em>int</em> <dfn class="local col8 decl" id="18iTerm" title='iTerm' data-type='int' data-ref="18iTerm" data-ref-filename="18iTerm">iTerm</dfn>, <em>int</em> <dfn class="local col9 decl" id="19iCol" title='iCol' data-type='int' data-ref="19iCol" data-ref-filename="19iCol">iCol</dfn>);</td></tr>
<tr><th id="158">158</th><td><em>int</em> <dfn class="decl fn" id="fts3_term_cnt" title='fts3_term_cnt' data-ref="fts3_term_cnt" data-ref-filename="fts3_term_cnt">fts3_term_cnt</dfn>(<em>int</em> <dfn class="local col0 decl" id="20iTerm" title='iTerm' data-type='int' data-ref="20iTerm" data-ref-filename="20iTerm">iTerm</dfn>, <em>int</em> <dfn class="local col1 decl" id="21iCol" title='iCol' data-type='int' data-ref="21iCol" data-ref-filename="21iCol">iCol</dfn>);</td></tr>
<tr><th id="159">159</th><td></td></tr>
<tr><th id="160">160</th><td></td></tr>
<tr><th id="161">161</th><td><u>#<span data-ppcond="20">endif</span> /* _FTS3_TOKENIZER_H_ */</u></td></tr>
<tr><th id="162">162</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='apropos-utils.c.html'>netbsd/usr.sbin/makemandb/apropos-utils.c</a><br/>Generated on <em>2019-Jul-19</em> from project netbsd revision <em>f9da89e0d</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
